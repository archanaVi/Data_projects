<img src="https://bit.ly/2VnXWr2" alt="Ironhack Logo" width="100"/>

# Ironhack Data Bootcamp | Projects


## Overview

The goal of this project is to practice what I have learned in the APIs and Web Scraping chapter of this program. 
For this project, I choose both to obtain data by scraping Producthunt.com web pages. For the web scraping, I need to scrape the HTML from your chosen pages, parse the HTML to extract the necessary information, and either save the results into a CSV file.

## Technical Requirements

The technical requirements for this project are as follows:

* You must obtain data from an API using Python and/or 
* You must scrape and clean HTML from a web page using Python.
* The results should be one / two files - one containing the tabular results of your API request and the other containing the results of your web page scrape.
* Your code should be saved in a Jupyter Notebook and your results should be saved in a folder named output.
* You should include a README.md file that describes the steps you took and your thought process for obtaining data from the API and web page.

## Deliverables

* **A Jupyter Notebook file** - `Web_Scraping_Producthunt` contains the code used to work with your API and/or scrape the  web page.
* **A CSV file** containing a saved version of the dataframe with scraped data
* **A ``README.md`` file** explaining the content of the project


## Suggested Ways to Get Started

* **Find an API to work with** - a great place to start looking would be [API List](https://apilist.fun/) and [Public APIs](https://github.com/toddmotto/public-apis). If you need authorization for your chosen API, make sure to give yourself enough time for the service to review and accept your application. Have a couple back-up APIs chosen just in case!
* **Find a web page to scrape** and determine the content you would like to scrape from it - blogs and news sites are typically good candidates for scraping text content, and [Wikipedia](https://www.wikipedia.org/) is usually a good source for HTML tables (search for "list of...").
* **Break the project down into different steps** - note the steps covered in the API and web scraping lessons, try to follow them, and make adjustments as you encounter the obstacles that are inevitable due to all APIs and web pages being different.
* **Use the tools in your tool kit** - your knowledge of intermediate Python as well as some of the things you've learned in previous chapters. This is a great way to start tying everything you've learned together!
* **Work through the lessons in class** & ask questions when you need to! Think about adding relevant code to your project each night, instead of, you know... _procrastinating_.
* **Commit early, commit often**, donâ€™t be afraid of doing something incorrectly because you can always roll back to a previous version.
* **Consult documentation and resources provided** to better understand the tools you are using and how to accomplish what you want.



